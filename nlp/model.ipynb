{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Input\n",
    "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D\n",
    "from keras.layers import LSTM, Bidirectional, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparamter\n",
    "DATA_DIR = \"../data/\"\n",
    "output_dir = '../data/lstm/'\n",
    "\n",
    "#data\n",
    "test_size = 0.1\n",
    "random_state = 12345\n",
    "\n",
    "#Training \n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "#vector-space embedding\n",
    "n_dim = 64\n",
    "n_unique_words = 5000\n",
    "max_review_length = 100\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.25\n",
    "\n",
    "#lstm architecture \n",
    "n_lstm = 256\n",
    "drop_lstm = 0.2\n",
    "\n",
    "#optimizer\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1158/51915 [00:09<07:17, 116.13it/s]/home/bt0/16CS10053/anaconda3/envs/cgcnn/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|██████████| 51915/51915 [02:19<00:00, 371.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data, labels = [],[]\n",
    "for file in tqdm(os.listdir(DATA_DIR+'pickled/')):\n",
    "    with open(DATA_DIR+'pickled/'+file,'rb') as f:\n",
    "        text,label = pickle.load(f)\n",
    "        data.append(text)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51915"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = MultiLabelBinarizer()\n",
    "labels = one_hot.fit_transform(labels)\n",
    "len(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x, train_y, test_y = train_test_split(data, labels, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46723, 46723, 5192, 5192)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x), len(train_y), len(test_x), len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [x for x in train_y.transpose()]\n",
    "test_y = [x for x in test_y.transpose()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bt0/16CS10053/anaconda3/envs/cgcnn/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/bt0/16CS10053/anaconda3/envs/cgcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 64)      1600000     inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128)          66048       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "FC_10 (Dense)                   (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_11 (Dense)                   (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_12 (Dense)                   (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_13 (Dense)                   (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_14 (Dense)                   (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_15 (Dense)                   (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_16 (Dense)                   (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_17 (Dense)                   (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_18 (Dense)                   (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_19 (Dense)                   (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_110 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_111 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_112 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_113 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_114 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_115 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_116 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_117 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_118 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_119 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_120 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_121 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_122 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_123 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_124 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_125 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_126 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_127 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_128 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_129 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_130 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_131 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_132 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_133 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_134 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_135 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_136 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_137 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_138 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_139 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_140 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_141 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_142 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_143 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_144 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_145 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_146 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_147 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_148 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_149 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_150 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_151 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_152 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_153 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_154 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_155 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_156 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_157 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_158 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_159 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_160 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_161 (Dense)                  (None, 64)           8256        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FC_20 (Dense)                   (None, 1)            65          FC_10[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC_21 (Dense)                   (None, 1)            65          FC_11[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC_22 (Dense)                   (None, 1)            65          FC_12[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC_23 (Dense)                   (None, 1)            65          FC_13[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC_24 (Dense)                   (None, 1)            65          FC_14[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC_25 (Dense)                   (None, 1)            65          FC_15[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC_26 (Dense)                   (None, 1)            65          FC_16[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC_27 (Dense)                   (None, 1)            65          FC_17[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC_28 (Dense)                   (None, 1)            65          FC_18[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC_29 (Dense)                   (None, 1)            65          FC_19[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC_210 (Dense)                  (None, 1)            65          FC_110[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_211 (Dense)                  (None, 1)            65          FC_111[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_212 (Dense)                  (None, 1)            65          FC_112[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_213 (Dense)                  (None, 1)            65          FC_113[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_214 (Dense)                  (None, 1)            65          FC_114[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_215 (Dense)                  (None, 1)            65          FC_115[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_216 (Dense)                  (None, 1)            65          FC_116[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_217 (Dense)                  (None, 1)            65          FC_117[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_218 (Dense)                  (None, 1)            65          FC_118[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_219 (Dense)                  (None, 1)            65          FC_119[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_220 (Dense)                  (None, 1)            65          FC_120[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_221 (Dense)                  (None, 1)            65          FC_121[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_222 (Dense)                  (None, 1)            65          FC_122[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_223 (Dense)                  (None, 1)            65          FC_123[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_224 (Dense)                  (None, 1)            65          FC_124[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_225 (Dense)                  (None, 1)            65          FC_125[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_226 (Dense)                  (None, 1)            65          FC_126[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_227 (Dense)                  (None, 1)            65          FC_127[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_228 (Dense)                  (None, 1)            65          FC_128[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_229 (Dense)                  (None, 1)            65          FC_129[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_230 (Dense)                  (None, 1)            65          FC_130[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_231 (Dense)                  (None, 1)            65          FC_131[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_232 (Dense)                  (None, 1)            65          FC_132[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_233 (Dense)                  (None, 1)            65          FC_133[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_234 (Dense)                  (None, 1)            65          FC_134[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_235 (Dense)                  (None, 1)            65          FC_135[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_236 (Dense)                  (None, 1)            65          FC_136[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_237 (Dense)                  (None, 1)            65          FC_137[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_238 (Dense)                  (None, 1)            65          FC_138[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_239 (Dense)                  (None, 1)            65          FC_139[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_240 (Dense)                  (None, 1)            65          FC_140[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_241 (Dense)                  (None, 1)            65          FC_141[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_242 (Dense)                  (None, 1)            65          FC_142[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_243 (Dense)                  (None, 1)            65          FC_143[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_244 (Dense)                  (None, 1)            65          FC_144[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_245 (Dense)                  (None, 1)            65          FC_145[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_246 (Dense)                  (None, 1)            65          FC_146[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_247 (Dense)                  (None, 1)            65          FC_147[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_248 (Dense)                  (None, 1)            65          FC_148[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_249 (Dense)                  (None, 1)            65          FC_149[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_250 (Dense)                  (None, 1)            65          FC_150[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_251 (Dense)                  (None, 1)            65          FC_151[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_252 (Dense)                  (None, 1)            65          FC_152[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_253 (Dense)                  (None, 1)            65          FC_153[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_254 (Dense)                  (None, 1)            65          FC_154[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_255 (Dense)                  (None, 1)            65          FC_155[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_256 (Dense)                  (None, 1)            65          FC_156[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_257 (Dense)                  (None, 1)            65          FC_157[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_258 (Dense)                  (None, 1)            65          FC_158[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_259 (Dense)                  (None, 1)            65          FC_159[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_260 (Dense)                  (None, 1)            65          FC_160[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_261 (Dense)                  (None, 1)            65          FC_161[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           FC_20[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1)            0           FC_21[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1)            0           FC_22[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1)            0           FC_23[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1)            0           FC_24[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1)            0           FC_25[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1)            0           FC_26[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1)            0           FC_27[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1)            0           FC_28[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1)            0           FC_29[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1)            0           FC_210[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1)            0           FC_211[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1)            0           FC_212[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1)            0           FC_213[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 1)            0           FC_214[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 1)            0           FC_215[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 1)            0           FC_216[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 1)            0           FC_217[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 1)            0           FC_218[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1)            0           FC_219[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 1)            0           FC_220[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 1)            0           FC_221[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 1)            0           FC_222[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1)            0           FC_223[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 1)            0           FC_224[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 1)            0           FC_225[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1)            0           FC_226[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 1)            0           FC_227[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 1)            0           FC_228[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 1)            0           FC_229[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 1)            0           FC_230[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1)            0           FC_231[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 1)            0           FC_232[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 1)            0           FC_233[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1)            0           FC_234[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1)            0           FC_235[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 1)            0           FC_236[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1)            0           FC_237[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 1)            0           FC_238[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1)            0           FC_239[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 1)            0           FC_240[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1)            0           FC_241[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 1)            0           FC_242[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1)            0           FC_243[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 1)            0           FC_244[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 1)            0           FC_245[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1)            0           FC_246[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 1)            0           FC_247[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 1)            0           FC_248[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 1)            0           FC_249[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 1)            0           FC_250[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 1)            0           FC_251[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1)            0           FC_252[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 1)            0           FC_253[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 1)            0           FC_254[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 1)            0           FC_255[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 1)            0           FC_256[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 1)            0           FC_257[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 1)            0           FC_258[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1)            0           FC_259[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 1)            0           FC_260[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 1)            0           FC_261[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,181,950\n",
      "Trainable params: 2,181,950\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_WORDS=25000\n",
    "train_with_cat=[]\n",
    "MAX_LEN=100\n",
    "\n",
    "tok_1=Tokenizer(num_words=MAX_WORDS)\n",
    "tok_1.fit_on_texts(train_x)                                                       #converting text input to vector\n",
    "sequences = tok_1.texts_to_sequences(train_x)                                     #to convert sentence to sequences of numbers\n",
    "sequences_matrix = sequence.pad_sequences(sequences, maxlen=MAX_LEN)\n",
    "def RNN_1():\n",
    "    inputs = Input(name='inputs', shape=[MAX_LEN])\n",
    "    layer = Embedding(MAX_WORDS, 64, input_length=MAX_LEN)(inputs)  \n",
    "    layer = Bidirectional(LSTM(64,recurrent_dropout=0.1,kernel_regularizer=regularizers.l2(0.000014),activity_regularizer=regularizers.l1(0.00012)))(layer)\n",
    "    layer_lst=[]\n",
    "    sigmoid_lst=[]\n",
    "    for i in range(len(train_y)):\n",
    "        layer_temp=Dense(64,name='FC_1'+str(i),kernel_regularizer=regularizers.l2(0.000013))(layer)\n",
    "        temp=Dense(1,name='FC_2'+str(i),kernel_regularizer=regularizers.l2(0.000013))(layer_temp)\n",
    "        sigmoid_lst.append(Activation('sigmoid')(temp))\n",
    "\n",
    "    model = Model(inputs=inputs,outputs=sigmoid_lst)\n",
    "    return model\n",
    "model = RNN_1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42050 samples, validate on 4673 samples\n",
      "Epoch 1/20\n",
      "42050/42050 [==============================] - 74s 2ms/step - loss: 4.3486 - activation_1_loss: 0.0028 - activation_2_loss: 0.0793 - activation_3_loss: 0.0686 - activation_4_loss: 0.0267 - activation_5_loss: 0.0033 - activation_6_loss: 0.0024 - activation_7_loss: 0.0591 - activation_8_loss: 0.1028 - activation_9_loss: 0.0039 - activation_10_loss: 0.0768 - activation_11_loss: 0.2309 - activation_12_loss: 0.0024 - activation_13_loss: 0.3300 - activation_14_loss: 0.0505 - activation_15_loss: 0.0752 - activation_16_loss: 0.1469 - activation_17_loss: 0.1786 - activation_18_loss: 0.0784 - activation_19_loss: 0.0759 - activation_20_loss: 2.9083e-04 - activation_21_loss: 0.0553 - activation_22_loss: 0.0465 - activation_23_loss: 0.0330 - activation_24_loss: 0.0382 - activation_25_loss: 0.0062 - activation_26_loss: 0.0736 - activation_27_loss: 0.0900 - activation_28_loss: 0.0110 - activation_29_loss: 0.0093 - activation_30_loss: 0.0440 - activation_31_loss: 0.0186 - activation_32_loss: 0.0926 - activation_33_loss: 0.1672 - activation_34_loss: 0.0374 - activation_35_loss: 0.0164 - activation_36_loss: 0.0087 - activation_37_loss: 0.0013 - activation_38_loss: 0.2052 - activation_39_loss: 0.2103 - activation_40_loss: 0.0154 - activation_41_loss: 0.0260 - activation_42_loss: 0.0103 - activation_43_loss: 0.0069 - activation_44_loss: 0.1294 - activation_45_loss: 0.0179 - activation_46_loss: 0.0103 - activation_47_loss: 0.5230 - activation_48_loss: 0.0036 - activation_49_loss: 0.0705 - activation_50_loss: 0.0709 - activation_51_loss: 0.0098 - activation_52_loss: 0.2005 - activation_53_loss: 0.0049 - activation_54_loss: 0.0634 - activation_55_loss: 0.0086 - activation_56_loss: 0.0039 - activation_57_loss: 0.0355 - activation_58_loss: 0.0406 - activation_59_loss: 0.0612 - activation_60_loss: 0.0065 - activation_61_loss: 0.0150 - activation_62_loss: 0.0403 - activation_1_acc: 0.9997 - activation_2_acc: 0.9820 - activation_3_acc: 0.9856 - activation_4_acc: 0.9953 - activation_5_acc: 0.9996 - activation_6_acc: 0.9997 - activation_7_acc: 0.9820 - activation_8_acc: 0.9753 - activation_9_acc: 0.9995 - activation_10_acc: 0.9785 - activation_11_acc: 0.9087 - activation_12_acc: 0.9998 - activation_13_acc: 0.8783 - activation_14_acc: 0.9875 - activation_15_acc: 0.9820 - activation_16_acc: 0.9608 - activation_17_acc: 0.9394 - activation_18_acc: 0.9703 - activation_19_acc: 0.9830 - activation_20_acc: 1.0000 - activation_21_acc: 0.9837 - activation_22_acc: 0.9867 - activation_23_acc: 0.9938 - activation_24_acc: 0.9923 - activation_25_acc: 0.9992 - activation_26_acc: 0.9733 - activation_27_acc: 0.9723 - activation_28_acc: 0.9983 - activation_29_acc: 0.9987 - activation_30_acc: 0.9906 - activation_31_acc: 0.9968 - activation_32_acc: 0.9707 - activation_33_acc: 0.9454 - activation_34_acc: 0.9903 - activation_35_acc: 0.9974 - activation_36_acc: 0.9988 - activation_37_acc: 0.9999 - activation_38_acc: 0.9079 - activation_39_acc: 0.9140 - activation_40_acc: 0.9976 - activation_41_acc: 0.9952 - activation_42_acc: 0.9984 - activation_43_acc: 0.9990 - activation_44_acc: 0.9670 - activation_45_acc: 0.9971 - activation_46_acc: 0.9986 - activation_47_acc: 0.7530 - activation_48_acc: 0.9996 - activation_49_acc: 0.9760 - activation_50_acc: 0.9759 - activation_51_acc: 0.9985 - activation_52_acc: 0.9082 - activation_53_acc: 0.9994 - activation_54_acc: 0.9858 - activation_55_acc: 0.9988 - activation_56_acc: 0.9995 - activation_57_acc: 0.9936 - activation_58_acc: 0.9906 - activation_59_acc: 0.9870 - activation_60_acc: 0.9990 - activation_61_acc: 0.9976 - activation_62_acc: 0.9915 - val_loss: 4.5665 - val_activation_1_loss: 7.7578e-05 - val_activation_2_loss: 0.1032 - val_activation_3_loss: 0.0573 - val_activation_4_loss: 0.0309 - val_activation_5_loss: 2.1573e-04 - val_activation_6_loss: 0.0018 - val_activation_7_loss: 0.0599 - val_activation_8_loss: 0.1117 - val_activation_9_loss: 0.0019 - val_activation_10_loss: 0.0670 - val_activation_11_loss: 0.2226 - val_activation_12_loss: 0.0077 - val_activation_13_loss: 0.3457 - val_activation_14_loss: 0.0578 - val_activation_15_loss: 0.0714 - val_activation_16_loss: 0.1422 - val_activation_17_loss: 0.1906 - val_activation_18_loss: 0.0878 - val_activation_19_loss: 0.0770 - val_activation_20_loss: 7.1995e-06 - val_activation_21_loss: 0.0568 - val_activation_22_loss: 0.0495 - val_activation_23_loss: 0.0504 - val_activation_24_loss: 0.0461 - val_activation_25_loss: 0.0064 - val_activation_26_loss: 0.0826 - val_activation_27_loss: 0.1080 - val_activation_28_loss: 0.0136 - val_activation_29_loss: 0.0103 - val_activation_30_loss: 0.0444 - val_activation_31_loss: 0.0139 - val_activation_32_loss: 0.0999 - val_activation_33_loss: 0.1914 - val_activation_34_loss: 0.0315 - val_activation_35_loss: 0.0140 - val_activation_36_loss: 0.0105 - val_activation_37_loss: 0.0022 - val_activation_38_loss: 0.2166 - val_activation_39_loss: 0.2274 - val_activation_40_loss: 0.0160 - val_activation_41_loss: 0.0293 - val_activation_42_loss: 0.0089 - val_activation_43_loss: 0.0106 - val_activation_44_loss: 0.1358 - val_activation_45_loss: 0.0171 - val_activation_46_loss: 0.0124 - val_activation_47_loss: 0.5340 - val_activation_48_loss: 0.0018 - val_activation_49_loss: 0.0777 - val_activation_50_loss: 0.0703 - val_activation_51_loss: 0.0062 - val_activation_52_loss: 0.2236 - val_activation_53_loss: 0.0049 - val_activation_54_loss: 0.0807 - val_activation_55_loss: 0.0091 - val_activation_56_loss: 0.0050 - val_activation_57_loss: 0.0434 - val_activation_58_loss: 0.0473 - val_activation_59_loss: 0.0580 - val_activation_60_loss: 7.9850e-04 - val_activation_61_loss: 0.0218 - val_activation_62_loss: 0.0452 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9762 - val_activation_3_acc: 0.9891 - val_activation_4_acc: 0.9949 - val_activation_5_acc: 1.0000 - val_activation_6_acc: 0.9998 - val_activation_7_acc: 0.9820 - val_activation_8_acc: 0.9730 - val_activation_9_acc: 0.9998 - val_activation_10_acc: 0.9814 - val_activation_11_acc: 0.9140 - val_activation_12_acc: 0.9991 - val_activation_13_acc: 0.8767 - val_activation_14_acc: 0.9867 - val_activation_15_acc: 0.9833 - val_activation_16_acc: 0.9634 - val_activation_17_acc: 0.9330 - val_activation_18_acc: 0.9679 - val_activation_19_acc: 0.9840 - val_activation_20_acc: 1.0000 - val_activation_21_acc: 0.9820 - val_activation_22_acc: 0.9878 - val_activation_23_acc: 0.9897 - val_activation_24_acc: 0.9910 - val_activation_25_acc: 0.9991 - val_activation_26_acc: 0.9722 - val_activation_27_acc: 0.9688 - val_activation_28_acc: 0.9979 - val_activation_29_acc: 0.9985 - val_activation_30_acc: 0.9906 - val_activation_31_acc: 0.9976 - val_activation_32_acc: 0.9688 - val_activation_33_acc: 0.9392 - val_activation_34_acc: 0.9908 - val_activation_35_acc: 0.9976 - val_activation_36_acc: 0.9985 - val_activation_37_acc: 0.9998 - val_activation_38_acc: 0.9065 - val_activation_39_acc: 0.9061 - val_activation_40_acc: 0.9976 - val_activation_41_acc: 0.9947 - val_activation_42_acc: 0.9987 - val_activation_43_acc: 0.9985 - val_activation_44_acc: 0.9660 - val_activation_45_acc: 0.9972 - val_activation_46_acc: 0.9983 - val_activation_47_acc: 0.7507 - val_activation_48_acc: 0.9998 - val_activation_49_acc: 0.9730 - val_activation_50_acc: 0.9756 - val_activation_51_acc: 0.9991 - val_activation_52_acc: 0.8949 - val_activation_53_acc: 0.9994 - val_activation_54_acc: 0.9816 - val_activation_55_acc: 0.9987 - val_activation_56_acc: 0.9996 - val_activation_57_acc: 0.9925 - val_activation_58_acc: 0.9889 - val_activation_59_acc: 0.9882 - val_activation_60_acc: 1.0000 - val_activation_61_acc: 0.9966 - val_activation_62_acc: 0.9912\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  256/42050 [..............................] - ETA: 55s - loss: 4.0104 - activation_1_loss: 7.0312e-05 - activation_2_loss: 0.0593 - activation_3_loss: 0.0681 - activation_4_loss: 0.0402 - activation_5_loss: 1.8244e-04 - activation_6_loss: 1.0752e-04 - activation_7_loss: 0.0206 - activation_8_loss: 0.1403 - activation_9_loss: 2.8101e-04 - activation_10_loss: 0.0522 - activation_11_loss: 0.1681 - activation_12_loss: 8.9676e-05 - activation_13_loss: 0.3777 - activation_14_loss: 0.0967 - activation_15_loss: 0.0956 - activation_16_loss: 0.1200 - activation_17_loss: 0.1947 - activation_18_loss: 0.0762 - activation_19_loss: 0.0705 - activation_20_loss: 7.0583e-06 - activation_21_loss: 0.0246 - activation_22_loss: 0.0216 - activation_23_loss: 0.0058 - activation_24_loss: 0.0351 - activation_25_loss: 9.9328e-04 - activation_26_loss: 0.0646 - activation_27_loss: 0.0565 - activation_28_loss: 0.0438 - activation_29_loss: 0.0013 - activation_30_loss: 0.0097 - activation_31_loss: 0.0024 - activation_32_loss: 0.1096 - activation_33_loss: 0.1380 - activation_34_loss: 0.0315 - activation_35_loss: 0.0021 - activation_36_loss: 0.0294 - activation_37_loss: 3.1346e-05 - activation_38_loss: 0.2186 - activation_39_loss: 0.1274 - activation_40_loss: 0.0233 - activation_41_loss: 0.0196 - activation_42_loss: 0.0220 - activation_43_loss: 5.7366e-04 - activation_44_loss: 0.1214 - activation_45_loss: 0.0260 - activation_46_loss: 0.0011 - activation_47_loss: 0.5230 - activation_48_loss: 3.0902e-04 - activation_49_loss: 0.0625 - activation_50_loss: 0.0491 - activation_51_loss: 9.5321e-04 - activation_52_loss: 0.1938 - activation_53_loss: 5.2480e-04 - activation_54_loss: 0.0353 - activation_55_loss: 0.0223 - activation_56_loss: 1.3496e-04 - activation_57_loss: 0.0203 - activation_58_loss: 0.0670 - activation_59_loss: 0.0561 - activation_60_loss: 9.4752e-04 - activation_61_loss: 0.0019 - activation_62_loss: 0.0482 - activation_1_acc: 1.0000 - activation_2_acc: 0.9844 - activation_3_acc: 0.9844 - activation_4_acc: 0.9922 - activation_5_acc: 1.0000 - activation_6_acc: 1.0000 - activation_7_acc: 0.9922 - activation_8_acc: 0.9648 - activation_9_acc: 1.0000 - activation_10_acc: 0.9805 - activation_11_acc: 0.9336 - activation_12_acc: 1.0000 - activation_13_acc: 0.8555 - activation_14_acc: 0.9766 - activation_15_acc: 0.9766 - activation_16_acc: 0.9648 - activation_17_acc: 0.9453 - activation_18_acc: 0.9609 - activation_19_acc: 0.9844 - activation_20_acc: 1.0000 - activation_21_acc: 0.9922 - activation_22_acc: 0.9922 - activation_23_acc: 1.0000 - activation_24_acc: 0.9922 - activation_25_acc: 1.0000 - activation_26_acc: 0.9727 - activation_27_acc: 0.9766 - activation_28_acc: 0.9922 - activation_29_acc: 1.0000 - activation_30_acc: 1.0000 - activation_31_acc: 1.0000 - activation_32_acc: 0.9570 - activation_33_acc: 0.9570 - activation_34_acc: 0.9883 - activation_35_acc: 1.0000 - activation_36_acc: 0.9961 - activation_37_acc: 1.0000 - activation_38_acc: 0.8906 - activation_39_acc: 0.9453 - activation_40_acc: 0.9961 - activation_41_acc: 0.9961 - activation_42_acc: 0.9961 - activation_43_acc: 1.0000 - activation_44_acc: 0.9727 - activation_45_acc: 0.9961 - activation_46_acc: 1.0000 - activation_47_acc: 0.7734 - activation_48_acc: 1.0000 - activation_49_acc: 0.9766 - activation_50_acc: 0.9805 - activation_51_acc: 1.0000 - activation_52_acc: 0.9023 - activation_53_acc: 1.0000 - activation_54_acc: 0.9961 - activation_55_acc: 0.9961 - activation_56_acc: 1.0000 - activation_57_acc: 0.9961 - activation_58_acc: 0.9844 - activation_59_acc: 0.9922 - activation_60_acc: 1.0000 - activation_61_acc: 1.0000 - activation_62_acc: 0.9922    42050/42050 [==============================] - 54s 1ms/step - loss: 4.1414 - activation_1_loss: 0.0027 - activation_2_loss: 0.0772 - activation_3_loss: 0.0672 - activation_4_loss: 0.0260 - activation_5_loss: 0.0033 - activation_6_loss: 0.0024 - activation_7_loss: 0.0496 - activation_8_loss: 0.0991 - activation_9_loss: 0.0038 - activation_10_loss: 0.0674 - activation_11_loss: 0.2230 - activation_12_loss: 0.0023 - activation_13_loss: 0.3208 - activation_14_loss: 0.0472 - activation_15_loss: 0.0722 - activation_16_loss: 0.1410 - activation_17_loss: 0.1653 - activation_18_loss: 0.0747 - activation_19_loss: 0.0740 - activation_20_loss: 2.9302e-04 - activation_21_loss: 0.0486 - activation_22_loss: 0.0386 - activation_23_loss: 0.0320 - activation_24_loss: 0.0362 - activation_25_loss: 0.0059 - activation_26_loss: 0.0697 - activation_27_loss: 0.0827 - activation_28_loss: 0.0104 - activation_29_loss: 0.0091 - activation_30_loss: 0.0412 - activation_31_loss: 0.0181 - activation_32_loss: 0.0869 - activation_33_loss: 0.1600 - activation_34_loss: 0.0326 - activation_35_loss: 0.0158 - activation_36_loss: 0.0082 - activation_37_loss: 0.0013 - activation_38_loss: 0.1917 - activation_39_loss: 0.1960 - activation_40_loss: 0.0153 - activation_41_loss: 0.0252 - activation_42_loss: 0.0099 - activation_43_loss: 0.0066 - activation_44_loss: 0.1259 - activation_45_loss: 0.0174 - activation_46_loss: 0.0098 - activation_47_loss: 0.5154 - activation_48_loss: 0.0034 - activation_49_loss: 0.0640 - activation_50_loss: 0.0654 - activation_51_loss: 0.0097 - activation_52_loss: 0.1913 - activation_53_loss: 0.0047 - activation_54_loss: 0.0613 - activation_55_loss: 0.0084 - activation_56_loss: 0.0040 - activation_57_loss: 0.0346 - activation_58_loss: 0.0397 - activation_59_loss: 0.0597 - activation_60_loss: 0.0063 - activation_61_loss: 0.0147 - activation_62_loss: 0.0382 - activation_1_acc: 0.9997 - activation_2_acc: 0.9820 - activation_3_acc: 0.9856 - activation_4_acc: 0.9953 - activation_5_acc: 0.9996 - activation_6_acc: 0.9997 - activation_7_acc: 0.9853 - activation_8_acc: 0.9753 - activation_9_acc: 0.9995 - activation_10_acc: 0.9799 - activation_11_acc: 0.9126 - activation_12_acc: 0.9998 - activation_13_acc: 0.8795 - activation_14_acc: 0.9876 - activation_15_acc: 0.9820 - activation_16_acc: 0.9608 - activation_17_acc: 0.9452 - activation_18_acc: 0.9712 - activation_19_acc: 0.9830 - activation_20_acc: 1.0000 - activation_21_acc: 0.9850 - activation_22_acc: 0.9891 - activation_23_acc: 0.9938 - activation_24_acc: 0.9923 - activation_25_acc: 0.9992 - activation_26_acc: 0.9742 - activation_27_acc: 0.9737 - activation_28_acc: 0.9983 - activation_29_acc: 0.9987 - activation_30_acc: 0.9907 - activation_31_acc: 0.9968 - activation_32_acc: 0.9729 - activation_33_acc: 0.9464 - activation_34_acc: 0.9904 - activation_35_acc: 0.9974 - activation_36_acc: 0.9988 - activation_37_acc: 0.9999 - activation_38_acc: 0.9154 - activation_39_acc: 0.9202 - activation_40_acc: 0.9976 - activation_41_acc: 0.9952 - activation_42_acc: 0.9984 - activation_43_acc: 0.9990 - activation_44_acc: 0.9670 - activation_45_acc: 0.9971 - activation_46_acc: 0.9986 - activation_47_acc: 0.7579 - activation_48_acc: 0.9996 - activation_49_acc: 0.9772 - activation_50_acc: 0.9772 - activation_51_acc: 0.9985 - activation_52_acc: 0.9125 - activation_53_acc: 0.9994 - activation_54_acc: 0.9858 - activation_55_acc: 0.9988 - activation_56_acc: 0.9995 - activation_57_acc: 0.9936 - activation_58_acc: 0.9906 - activation_59_acc: 0.9870 - activation_60_acc: 0.9990 - activation_61_acc: 0.9976 - activation_62_acc: 0.9915 - val_loss: 4.6146 - val_activation_1_loss: 1.8653e-04 - val_activation_2_loss: 0.1032 - val_activation_3_loss: 0.0566 - val_activation_4_loss: 0.0305 - val_activation_5_loss: 3.0464e-04 - val_activation_6_loss: 0.0019 - val_activation_7_loss: 0.0571 - val_activation_8_loss: 0.1112 - val_activation_9_loss: 0.0018 - val_activation_10_loss: 0.0667 - val_activation_11_loss: 0.2227 - val_activation_12_loss: 0.0072 - val_activation_13_loss: 0.3412 - val_activation_14_loss: 0.0550 - val_activation_15_loss: 0.0728 - val_activation_16_loss: 0.1430 - val_activation_17_loss: 0.1993 - val_activation_18_loss: 0.0886 - val_activation_19_loss: 0.0760 - val_activation_20_loss: 5.0161e-06 - val_activation_21_loss: 0.0604 - val_activation_22_loss: 0.0599 - val_activation_23_loss: 0.0495 - val_activation_24_loss: 0.0447 - val_activation_25_loss: 0.0070 - val_activation_26_loss: 0.0826 - val_activation_27_loss: 0.1069 - val_activation_28_loss: 0.0142 - val_activation_29_loss: 0.0100 - val_activation_30_loss: 0.0450 - val_activation_31_loss: 0.0156 - val_activation_32_loss: 0.1229 - val_activation_33_loss: 0.1959 - val_activation_34_loss: 0.0311 - val_activation_35_loss: 0.0134 - val_activation_36_loss: 0.0105 - val_activation_37_loss: 0.0023 - val_activation_38_loss: 0.2248 - val_activation_39_loss: 0.2284 - val_activation_40_loss: 0.0160 - val_activation_41_loss: 0.0292 - val_activation_42_loss: 0.0086 - val_activation_43_loss: 0.0105 - val_activation_44_loss: 0.1358 - val_activation_45_loss: 0.0177 - val_activation_46_loss: 0.0121 - val_activation_47_loss: 0.5385 - val_activation_48_loss: 0.0018 - val_activation_49_loss: 0.0798 - val_activation_50_loss: 0.0711 - val_activation_51_loss: 0.0059 - val_activation_52_loss: 0.2241 - val_activation_53_loss: 0.0047 - val_activation_54_loss: 0.0775 - val_activation_55_loss: 0.0094 - val_activation_56_loss: 0.0045 - val_activation_57_loss: 0.0437 - val_activation_58_loss: 0.0459 - val_activation_59_loss: 0.0578 - val_activation_60_loss: 3.7274e-04 - val_activation_61_loss: 0.0217 - val_activation_62_loss: 0.0437 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9762 - val_activation_3_acc: 0.9891 - val_activation_4_acc: 0.9949 - val_activation_5_acc: 1.0000 - val_activation_6_acc: 0.9998 - val_activation_7_acc: 0.9857 - val_activation_8_acc: 0.9730 - val_activation_9_acc: 0.9998 - val_activation_10_acc: 0.9842 - val_activation_11_acc: 0.9170 - val_activation_12_acc: 0.9991 - val_activation_13_acc: 0.8770 - val_activation_14_acc: 0.9867 - val_activation_15_acc: 0.9833 - val_activation_16_acc: 0.9640 - val_activation_17_acc: 0.9296 - val_activation_18_acc: 0.9692 - val_activation_19_acc: 0.9840 - val_activation_20_acc: 1.0000 - val_activation_21_acc: 0.9833 - val_activation_22_acc: 0.9872 - val_activation_23_acc: 0.9897 - val_activation_24_acc: 0.9910 - val_activation_25_acc: 0.9991 - val_activation_26_acc: 0.9737 - val_activation_27_acc: 0.9694 - val_activation_28_acc: 0.9979 - val_activation_29_acc: 0.9985 - val_activation_30_acc: 0.9906 - val_activation_31_acc: 0.9976 - val_activation_32_acc: 0.9651 - val_activation_33_acc: 0.9379 - val_activation_34_acc: 0.9910 - val_activation_35_acc: 0.9976 - val_activation_36_acc: 0.9985 - val_activation_37_acc: 0.9998 - val_activation_38_acc: 0.9028 - val_activation_39_acc: 0.9086 - val_activation_40_acc: 0.9976 - val_activation_41_acc: 0.9947 - val_activation_42_acc: 0.9987 - val_activation_43_acc: 0.9985 - val_activation_44_acc: 0.9660 - val_activation_45_acc: 0.9972 - val_activation_46_acc: 0.9983 - val_activation_47_acc: 0.7518 - val_activation_48_acc: 0.9998 - val_activation_49_acc: 0.9728 - val_activation_50_acc: 0.9758 - val_activation_51_acc: 0.9991 - val_activation_52_acc: 0.8947 - val_activation_53_acc: 0.9994 - val_activation_54_acc: 0.9816 - val_activation_55_acc: 0.9987 - val_activation_56_acc: 0.9996 - val_activation_57_acc: 0.9925 - val_activation_58_acc: 0.9889 - val_activation_59_acc: 0.9882 - val_activation_60_acc: 1.0000 - val_activation_61_acc: 0.9966 - val_activation_62_acc: 0.9912\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  128/42050 [..............................] - ETA: 51s - loss: 4.2961 - activation_1_loss: 1.5018e-04 - activation_2_loss: 0.0647 - activation_3_loss: 0.1545 - activation_4_loss: 0.0335 - activation_5_loss: 2.2392e-04 - activation_6_loss: 7.1360e-05 - activation_7_loss: 0.0456 - activation_8_loss: 0.1067 - activation_9_loss: 2.0719e-04 - activation_10_loss: 0.0965 - activation_11_loss: 0.2129 - activation_12_loss: 1.3776e-04 - activation_13_loss: 0.3368 - activation_14_loss: 0.0554 - activation_15_loss: 0.1020 - activation_16_loss: 0.2062 - activation_17_loss: 0.1615 - activation_18_loss: 0.0601 - activation_19_loss: 0.0546 - activation_20_loss: 4.9872e-06 - activation_21_loss: 0.0720 - activation_22_loss: 0.0614 - activation_23_loss: 0.0967 - activation_24_loss: 0.1120 - activation_25_loss: 6.5136e-04 - activation_26_loss: 0.0469 - activation_27_loss: 0.0359 - activation_28_loss: 0.0013 - activation_29_loss: 0.0012 - activation_30_loss: 0.0473 - activation_31_loss: 0.0320 - activation_32_loss: 0.1098 - activation_33_loss: 0.0895 - activation_34_loss: 0.0330 - activation_35_loss: 0.0031 - activation_36_loss: 0.0010 - activation_37_loss: 1.7030e-05 - activation_38_loss: 0.2185 - activation_39_loss: 0.1443 - activation_40_loss: 0.0021 - activation_41_loss: 0.0753 - activation_42_loss: 5.3285e-04 - activation_43_loss: 9.5335e-04 - activation_44_loss: 0.1223 - activation_45_loss: 0.0396 - activation_46_loss: 9.3355e-04 - activation_47_loss: 0.5576 - activation_48_loss: 1.8174e-04 - activation_49_loss: 0.0371 - activation_50_loss: 0.0752 - activation_51_loss: 0.0017 - activation_52_loss: 0.1799 - activation_53_loss: 3.1521e-04 - activation_54_loss: 0.0374 - activation_55_loss: 9.7376e-04 - activation_56_loss: 2.1162e-04 - activation_57_loss: 0.0532 - activation_58_loss: 0.0205 - activation_59_loss: 0.0329 - activation_60_loss: 3.0330e-04 - activation_61_loss: 0.0025 - activation_62_loss: 0.0422 - activation_1_acc: 1.0000 - activation_2_acc: 0.9844 - activation_3_acc: 0.9688 - activation_4_acc: 0.9922 - activation_5_acc: 1.0000 - activation_6_acc: 1.0000 - activation_7_acc: 0.9766 - activation_8_acc: 0.9688 - activation_9_acc: 1.0000 - activation_10_acc: 0.9766 - activation_11_acc: 0.8984 - activation_12_acc: 1.0000 - activation_13_acc: 0.8672 - activation_14_acc: 0.9844 - activation_15_acc: 0.9688 - activation_16_acc: 0.9375 - activation_17_acc: 0.9531 - activation_18_acc: 0.9609 - activation_19_acc: 0.9844 - activation_20_acc: 1.0000 - activation_21_acc: 0.9844 - activation_22_acc: 0.9844 - activation_23_acc: 0.9766 - activation_24_acc: 0.9688 - activation_25_acc: 1.0000 - activation_26_acc: 0.9688 - activation_27_acc: 0.9922 - activation_28_acc: 1.0000 - activation_29_acc: 1.0000 - activation_30_acc: 0.9844 - activation_31_acc: 0.9922 - activation_32_acc: 0.9766 - activation_33_acc: 0.9766 - activation_34_acc: 0.9922 - activation_35_acc: 1.0000 - activation_36_acc: 1.0000 - activation_37_acc: 1.0000 - activation_38_acc: 0.8984 - activation_39_acc: 0.9297 - activation_40_acc: 1.0000 - activation_41_acc: 0.9922 - activation_42_acc: 1.0000 - activation_43_acc: 1.0000 - activation_44_acc: 0.9609 - activation_45_acc: 0.9922 - activation_46_acc: 1.0000 - activation_47_acc: 0.6953 - activation_48_acc: 1.0000 - activation_49_acc: 0.9766 - activation_50_acc: 0.9688 - activation_51_acc: 1.0000 - activation_52_acc: 0.9297 - activation_53_acc: 1.0000 - activation_54_acc: 0.9922 - activation_55_acc: 1.0000 - activation_56_acc: 1.0000 - activation_57_acc: 0.9922 - activation_58_acc: 0.9922 - activation_59_acc: 0.9922 - activation_60_acc: 1.0000 - activation_61_acc: 1.0000 - activation_62_acc: 0.9922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  256/42050 [..............................] - ETA: 55s - loss: 4.2126 - activation_1_loss: 1.7534e-04 - activation_2_loss: 0.0815 - activation_3_loss: 0.1281 - activation_4_loss: 0.0185 - activation_5_loss: 2.6544e-04 - activation_6_loss: 7.6400e-05 - activation_7_loss: 0.0300 - activation_8_loss: 0.1014 - activation_9_loss: 2.2431e-04 - activation_10_loss: 0.0605 - activation_11_loss: 0.2211 - activation_12_loss: 1.4906e-04 - activation_13_loss: 0.3385 - activation_14_loss: 0.0442 - activation_15_loss: 0.0977 - activation_16_loss: 0.1969 - activation_17_loss: 0.1104 - activation_18_loss: 0.0795 - activation_19_loss: 0.0552 - activation_20_loss: 4.9938e-06 - activation_21_loss: 0.0859 - activation_22_loss: 0.0423 - activation_23_loss: 0.0605 - activation_24_loss: 0.0717 - activation_25_loss: 7.1641e-04 - activation_26_loss: 0.0602 - activation_27_loss: 0.0783 - activation_28_loss: 0.0014 - activation_29_loss: 0.0015 - activation_30_loss: 0.0685 - activation_31_loss: 0.0190 - activation_32_loss: 0.1066 - activation_33_loss: 0.1004 - activation_34_loss: 0.0268 - activation_35_loss: 0.0027 - activation_36_loss: 0.0010 - activation_37_loss: 1.7991e-05 - activation_38_loss: 0.2012 - activation_39_loss: 0.1802 - activation_40_loss: 0.0024 - activation_41_loss: 0.0397 - activation_42_loss: 6.7716e-04 - activation_43_loss: 8.0282e-04 - activation_44_loss: 0.1406 - activation_45_loss: 0.0221 - activation_46_loss: 9.4487e-04 - activation_47_loss: 0.5160 - activation_48_loss: 2.1323e-04 - activation_49_loss: 0.0312 - activation_50_loss: 0.0997 - activation_51_loss: 0.0017 - activation_52_loss: 0.2233 - activation_53_loss: 3.4967e-04 - activation_54_loss: 0.0267 - activation_55_loss: 9.3905e-04 - activation_56_loss: 2.5188e-04 - activation_57_loss: 0.0749 - activation_58_loss: 0.0425 - activation_59_loss: 0.0750 - activation_60_loss: 4.0698e-04 - activation_61_loss: 0.0024 - activation_62_loss: 0.0270 - activation_1_acc: 1.0000 - activation_2_acc: 0.9805 - activation_3_acc: 0.9727 - activation_4_acc: 0.9961 - activation_5_acc: 1.0000 - activation_6_acc: 1.0000 - activation_7_acc: 0.9883 - activation_8_acc: 0.9727 - activation_9_acc: 1.0000 - activation_10_acc: 0.9883 - activation_11_acc: 0.9023 - activation_12_acc: 1.0000 - activation_13_acc: 0.8750 - activation_14_acc: 0.9883 - activation_15_acc: 0.9688 - activation_16_acc: 0.9414 - activation_17_acc: 0.9688 - activation_18_acc: 0.9648 - activation_19_acc: 0.9844 - activation_20_acc: 1.0000 - activation_21_acc: 0.9805 - activation_22_acc: 0.9922 - activation_23_acc: 0.9844 - activation_24_acc: 0.9805 - activation_25_acc: 1.0000 - activation_26_acc: 0.9688 - activation_27_acc: 0.9805 - activation_28_acc: 1.0000 - activation_29_acc: 1.0000 - activation_30_acc: 0.9844 - activation_31_acc: 0.9961 - activation_32_acc: 0.9727 - activation_33_acc: 0.9688 - activation_34_acc: 0.9883 - activation_35_acc: 1.0000 - activation_36_acc: 1.0000 - activation_37_acc: 1.0000 - activation_38_acc: 0.8984 - activation_39_acc: 0.9297 - activation_40_acc: 1.0000 - activation_41_acc: 0.9961 - activation_42_acc: 1.0000 - activation_43_acc: 1.0000 - activation_44_acc: 0.9609 - activation_45_acc: 0.9961 - activation_46_acc: 1.0000 - activation_47_acc: 0.7266 - activation_48_acc: 1.0000 - activation_49_acc: 0.9844 - activation_50_acc: 0.9609 - activation_51_acc: 1.0000 - activation_52_acc: 0.9023 - activation_53_acc: 1.0000 - activation_54_acc: 0.9961 - activation_55_acc: 1.0000 - activation_56_acc: 1.0000 - activation_57_acc: 0.9844 - activation_58_acc: 0.9883 - activation_59_acc: 0.9844 - activation_60_acc: 1.0000 - activation_61_acc: 1.0000 - activation_62_acc: 0.9961"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38016/42050 [==========================>...] - ETA: 5s - loss: 3.9761 - activation_1_loss: 0.0027 - activation_2_loss: 0.0776 - activation_3_loss: 0.0638 - activation_4_loss: 0.0251 - activation_5_loss: 0.0027 - activation_6_loss: 0.0024 - activation_7_loss: 0.0432 - activation_8_loss: 0.0948 - activation_9_loss: 0.0037 - activation_10_loss: 0.0625 - activation_11_loss: 0.2146 - activation_12_loss: 0.0023 - activation_13_loss: 0.3122 - activation_14_loss: 0.0443 - activation_15_loss: 0.0696 - activation_16_loss: 0.1375 - activation_17_loss: 0.1542 - activation_18_loss: 0.0723 - activation_19_loss: 0.0718 - activation_20_loss: 3.3125e-04 - activation_21_loss: 0.0439 - activation_22_loss: 0.0340 - activation_23_loss: 0.0310 - activation_24_loss: 0.0354 - activation_25_loss: 0.0057 - activation_26_loss: 0.0661 - activation_27_loss: 0.0767 - activation_28_loss: 0.0094 - activation_29_loss: 0.0087 - activation_30_loss: 0.0405 - activation_31_loss: 0.0175 - activation_32_loss: 0.0803 - activation_33_loss: 0.1533 - activation_34_loss: 0.0299 - activation_35_loss: 0.0154 - activation_36_loss: 0.0088 - activation_37_loss: 0.0014 - activation_38_loss: 0.1814 - activation_39_loss: 0.1885 - activation_40_loss: 0.0150 - activation_41_loss: 0.0244 - activation_42_loss: 0.0099 - activation_43_loss: 0.0067 - activation_44_loss: 0.1233 - activation_45_loss: 0.0176 - activation_46_loss: 0.0098 - activation_47_loss: 0.5050 - activation_48_loss: 0.0033 - activation_49_loss: 0.0601 - activation_50_loss: 0.0601 - activation_51_loss: 0.0096 - activation_52_loss: 0.1802 - activation_53_loss: 0.0047 - activation_54_loss: 0.0590 - activation_55_loss: 0.0083 - activation_56_loss: 0.0039 - activation_57_loss: 0.0344 - activation_58_loss: 0.0391 - activation_59_loss: 0.0596 - activation_60_loss: 0.0065 - activation_61_loss: 0.0143 - activation_62_loss: 0.0361 - activation_1_acc: 0.9997 - activation_2_acc: 0.9816 - activation_3_acc: 0.9859 - activation_4_acc: 0.9954 - activation_5_acc: 0.9997 - activation_6_acc: 0.9997 - activation_7_acc: 0.9876 - activation_8_acc: 0.9754 - activation_9_acc: 0.9995 - activation_10_acc: 0.9813 - activation_11_acc: 0.9161 - activation_12_acc: 0.9997 - activation_13_acc: 0.8817 - activation_14_acc: 0.9881 - activation_15_acc: 0.9821 - activation_16_acc: 0.9608 - activation_17_acc: 0.9489 - activation_18_acc: 0.9710 - activation_19_acc: 0.9832 - activation_20_acc: 1.0000 - activation_21_acc: 0.9864 - activation_22_acc: 0.9903 - activation_23_acc: 0.9938 - activation_24_acc: 0.9922 - activation_25_acc: 0.9992 - activation_26_acc: 0.9747 - activation_27_acc: 0.9765 - activation_28_acc: 0.9985 - activation_29_acc: 0.9987 - activation_30_acc: 0.9907 - activation_31_acc: 0.9968 - activation_32_acc: 0.9747 - activation_33_acc: 0.9482 - activation_34_acc: 0.9903 - activation_35_acc: 0.9974 - activation_36_acc: 0.9987 - activation_37_acc: 0.9999 - activation_38_acc: 0.9231 - activation_39_acc: 0.9240 - activation_40_acc: 0.9976 - activation_41_acc: 0.9953 - activation_42_acc: 0.9984 - activation_43_acc: 0.9990 - activation_44_acc: 0.9672 - activation_45_acc: 0.9969 - activation_46_acc: 0.9986 - activation_47_acc: 0.7638 - activation_48_acc: 0.9996 - activation_49_acc: 0.9780 - activation_50_acc: 0.9789 - activation_51_acc: 0.9984 - activation_52_acc: 0.9188 - activation_53_acc: 0.9993 - activation_54_acc: 0.9858 - activation_55_acc: 0.9987 - activation_56_acc: 0.9995 - activation_57_acc: 0.9935 - activation_58_acc: 0.9906 - activation_59_acc: 0.9868 - activation_60_acc: 0.9990 - activation_61_acc: 0.9975 - activation_62_acc: 0.9916"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2f5f624b81a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           callbacks=[modelcheckpoint])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM2_main.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cgcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/cgcnn/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cgcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cgcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cgcnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(lr=0.0007),metrics=['accuracy'])\n",
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\", save_best_only=True)\n",
    "model.fit(sequences_matrix,\n",
    "          train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=2,\n",
    "          validation_split=0.1, \n",
    "          callbacks=[modelcheckpoint])\n",
    "model.save('LSTM2_main.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cgcnn]",
   "language": "python",
   "name": "conda-env-cgcnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
